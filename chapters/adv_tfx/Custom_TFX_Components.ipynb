{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_TFX_Components.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rxGlI475jTh"
      },
      "source": [
        "# Custom TFX Components\n",
        "\n",
        "## Download example dataset\n",
        "\n",
        "For this workshop we'll be using the public cats & dogs dataset created by Microsoft. The data set contains two folders: \"Dog\" and \"Cat\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-buPbpyo5lgm"
      },
      "source": [
        "!rm -rf /content/PetImages/\n",
        "!rm *.zip\n",
        "\n",
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "!unzip -q -d /content/ /content/kagglecatsanddogs_3367a.zip\n",
        "\n",
        "!echo \"Count images\"\n",
        "!ls -U /content/PetImages/Cat | wc -l\n",
        "!ls -U /content/PetImages/Dog | wc -l\n",
        "\n",
        "!echo \"Reduce images for demo purposes\"\n",
        "!cd /content/PetImages/Cat && ls -U | head -12000 | xargs rm \n",
        "!cd /content/PetImages/Dog && ls -U | head -12000 | xargs rm \n",
        "\n",
        "!echo \"Count images after removal\"\n",
        "!ls -U /content/PetImages/Cat | wc -l\n",
        "!ls -U /content/PetImages/Dog | wc -l\n",
        "\n",
        "!echo \"Rename filename and move them\"\n",
        "!rm -rf /content/images/\n",
        "!mkdir -p /content/images/\n",
        "%cd /content/PetImages/Cat\n",
        "!rename 's/^/cat-/' *.jpg\n",
        "!mv *.jpg /content/images/\n",
        "%cd /content/PetImages/Dog\n",
        "!rename 's/^/dog-/' *.jpg\n",
        "!mv *.jpg /content/images/\n",
        "!ls -U /content/images/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSOJwdKVPuR7"
      },
      "source": [
        "## Install required Python packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_HLg5-j5v29"
      },
      "source": [
        "!pip install tfx==0.27.0\n",
        "\n",
        "import tfx "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWVmbxJJI_M-"
      },
      "source": [
        "## Import required packages & modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAlDXeya7f-a"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, List, Text, Optional\n",
        "\n",
        "import absl\n",
        "import apache_beam as beam\n",
        "import tensorflow as tf\n",
        "import tfx\n",
        "from tfx import types\n",
        "from tfx.components import StatisticsGen\n",
        "from tfx.components.base import base_component, base_driver, base_executor, executor_spec\n",
        "from tfx.components.example_gen import driver, utils\n",
        "from tfx.components.example_gen.base_example_gen_executor import BaseExampleGenExecutor\n",
        "from tfx.components.example_gen.component import FileBasedExampleGen\n",
        "from tfx.orchestration import data_types, pipeline\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.proto import example_gen_pb2\n",
        "from tfx.types import Channel, artifact_utils, channel_utils, standard_artifacts\n",
        "from tfx.types.component_spec import ChannelParameter, ExecutionParameter\n",
        "from tfx.utils import proto_utils\n",
        "from tfx.utils.dsl_utils import external_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk30idMCd-Jh"
      },
      "source": [
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd9XyDkBQJBx"
      },
      "source": [
        "## Define helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrKzooGT8Km0"
      },
      "source": [
        "%%writefile {\"helpers.py\"}\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
        "    if not isinstance(value, list):\n",
        "        value = [value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def get_label_from_filename(filename):\n",
        "    \"\"\" Function to set the label for each image. In our case, we'll use the file \n",
        "    path of a label indicator. Based on your initial data \n",
        "    Args:\n",
        "      filename: string, full file path\n",
        "    Returns:\n",
        "      int - label\n",
        "    Raises:\n",
        "      NotImplementedError if not label category was detected\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    lowered_filename = filename.lower()\n",
        "    if \"dog\" in lowered_filename:\n",
        "        label = 0\n",
        "    elif \"cat\" in lowered_filename:\n",
        "        label = 1\n",
        "    else:\n",
        "        raise NotImplementedError(\"Found unknown image\")\n",
        "    return label\n",
        "    \n",
        "\n",
        "def _convert_to_example(image_buffer, label):\n",
        "    \"\"\"Function to convert image byte strings and labels into tf.Example structures\n",
        "      Args:\n",
        "        image_buffer: byte string representing the image\n",
        "        label: int\n",
        "      Returns:\n",
        "        TFExample data structure containing the image (byte string) and the label (int encoded)\n",
        "    \"\"\"\n",
        "\n",
        "    example = tf.train.Example(\n",
        "        features=tf.train.Features(\n",
        "            feature={\n",
        "                'image/raw': _bytes_feature(image_buffer),\n",
        "                'label': _int64_feature(label)\n",
        "            }))\n",
        "    return example\n",
        "\n",
        "\n",
        "def get_image_data(filename):\n",
        "    \"\"\"Process a single image file.\n",
        "    Args:\n",
        "      filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
        "    Returns:\n",
        "      TFExample data structure containing the image (byte string) and the label (int encoded)\n",
        "    \"\"\"\n",
        "    label = get_label_from_filename(filename)\n",
        "    byte_content = tf.io.read_file(filename)\n",
        "    rs = _convert_to_example(byte_content.numpy(), label)\n",
        "    return rs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHn3GHAm--B0"
      },
      "source": [
        "### Custom Component Specifications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjZ_QvArnl1"
      },
      "source": [
        "https://github.com/tensorflow/tfx/blob/master/tfx/types/standard_artifacts.py\n",
        "\n",
        "Difference between ChannelParameter and ExecutionParameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmxjmr4p-1nW"
      },
      "source": [
        "class CustomIngestionComponentSpec(types.ComponentSpec):\n",
        "    \"\"\"ComponentSpec for Custom Ingestion Component.\"\"\"\n",
        "    \n",
        "    PARAMETERS = {\n",
        "        'input_base':\n",
        "            ExecutionParameter(type=(str, Text))\n",
        "    }\n",
        "    INPUTS = {\n",
        "    }\n",
        "    OUTPUTS = {\n",
        "        'examples': ChannelParameter(type=standard_artifacts.Examples),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvpcpzhB_JO-"
      },
      "source": [
        "### Custom Component Executor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FEMWVdP_GhR"
      },
      "source": [
        "from helpers import get_image_data\n",
        "\n",
        "\n",
        "class CustomIngestionExecutor(base_executor.BaseExecutor):\n",
        "    \"\"\"Executor for CustomIngestionComponent.\"\"\"\n",
        "\n",
        "    def Do(self, input_dict: Dict[Text, List[types.Artifact]],\n",
        "          output_dict: Dict[Text, List[types.Artifact]],\n",
        "          exec_properties: Dict[Text, Any]) -> None:\n",
        "\n",
        "        input_base_uri = exec_properties[utils.INPUT_BASE_KEY]\n",
        "        image_files = tf.io.gfile.listdir(input_base_uri)\n",
        "        random.shuffle(image_files)\n",
        "\n",
        "        train_images, eval_images = image_files[100:], image_files[:100]\n",
        "        splits = [('train', train_images), ('eval', eval_images)]\n",
        "\n",
        "        examples_artifact = artifact_utils.get_single_instance(\n",
        "            output_dict[utils.EXAMPLES_KEY]\n",
        "        )\n",
        "        examples_artifact.split_names = artifact_utils.encode_split_names(['train', 'eval'])\n",
        "\n",
        "        for split_name, images in splits:\n",
        "            output_dir = artifact_utils.get_split_uri(\n",
        "                output_dict[utils.EXAMPLES_KEY], split_name)\n",
        "\n",
        "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "            tfrecords_filename = os.path.join(output_dir, 'images.tfrecords')\n",
        "            options = tf.io.TFRecordOptions(compression_type=None)\n",
        "            writer = tf.io.TFRecordWriter(tfrecords_filename, options=options)\n",
        "\n",
        "            for image_filename in images:\n",
        "                image_path = os.path.join(input_base_uri, image_filename)\n",
        "                example = get_image_data(image_path)\n",
        "                writer.write(example.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh5vr3Pa_VpD"
      },
      "source": [
        "### Custom Component Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjPrxM5X_Rdg"
      },
      "source": [
        "class CustomIngestionDriver(base_driver.BaseDriver):\n",
        "    \"\"\"Custom driver for CustomIngestion component.\n",
        "\n",
        "    This driver supports file based ExampleGen, it registers external file path as\n",
        "    an artifact, similar to the use cases CsvExampleGen and ImportExampleGen.\n",
        "    \"\"\"\n",
        "\n",
        "    def resolve_input_artifacts(\n",
        "        self,\n",
        "        input_channels: Dict[Text, types.Channel],\n",
        "        exec_properties: Dict[Text, Any],\n",
        "        driver_args: data_types.DriverArgs,\n",
        "        pipeline_info: data_types.PipelineInfo,\n",
        "    ) -> Dict[Text, List[types.Artifact]]:\n",
        "        \"\"\"Overrides BaseDriver.resolve_input_artifacts().\"\"\"\n",
        "        del driver_args  # unused\n",
        "        del pipeline_info  # unused\n",
        "\n",
        "        input_config = example_gen_pb2.Input()\n",
        "        input_dict = channel_utils.unwrap_channel_dict(input_channels)\n",
        "        for input_list in input_dict.values():\n",
        "            for single_input in input_list:\n",
        "                self._metadata_handler.publish_artifacts([single_input])\n",
        "                \n",
        "        return input_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKbYwCE_bZR"
      },
      "source": [
        "### Component Setup \n",
        "\n",
        "Putting all pieces together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qooyPE9X_agc"
      },
      "source": [
        "class CustomIngestionComponent(base_component.BaseComponent):\n",
        "    \"\"\"CustomIngestion Component.\"\"\"\n",
        "    SPEC_CLASS = CustomIngestionComponentSpec\n",
        "    EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(CustomIngestionExecutor)\n",
        "    DRIVER_CLASS = CustomIngestionDriver\n",
        "\n",
        "    def __init__(self,\n",
        "                input_base: Optional[Text] = None,\n",
        "                output_data: types.Channel = None):\n",
        "      if not output_data:\n",
        "          output_data = types.Channel(type=standard_artifacts.Examples)\n",
        "\n",
        "      spec = CustomIngestionComponentSpec(\n",
        "          input_base=input_base,\n",
        "          examples=output_data,\n",
        "      )\n",
        "      super(CustomIngestionComponent, self).__init__(spec=spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPsN9SQN_muf"
      },
      "source": [
        "## Basic Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiPWvcY4_g_w"
      },
      "source": [
        "context = InteractiveContext()\n",
        "\n",
        "data_root = '/content/images'\n",
        "\n",
        "ingest_images = CustomIngestionComponent(\n",
        "    input_base=data_root\n",
        ")\n",
        "context.run(ingest_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8BACeQCS2jw"
      },
      "source": [
        "filepath = '{}/train/images.tfrecords'.format(ingest_images.outputs['examples'].get()[0].uri)\n",
        "dataset = tf.data.TFRecordDataset([filepath])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXIfi3xfTQxX"
      },
      "source": [
        "for data in dataset.take(1):\n",
        "  print(tf.train.Example.FromString(data.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUL5vJh0_uyl"
      },
      "source": [
        "statistics_gen = StatisticsGen(\n",
        "    examples=ingest_images.outputs['examples'])\n",
        "context.run(statistics_gen)\n",
        "\n",
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Go6dW3AeQpM"
      },
      "source": [
        "## Implement a component by overwriting the component executor\n",
        "\n",
        "![TFX **Component**](https://drive.google.com/uc?export=view&id=1Hg-iUp8UF5Jh3dpdL-htG-Cw5g7GKqF3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IVtoSoBma8h"
      },
      "source": [
        "### Thinks to know:\n",
        "\n",
        "* Decorator `@beam.ptransform_fn`: https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/ptransform.py\n",
        "* `BaseExampleGenExecutor` class: https://github.com/tensorflow/tfx/blob/v0.22.1/tfx/components/example_gen/base_example_gen_executor.py#L90-L243"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNVTLErTx7B9"
      },
      "source": [
        "from helpers import get_image_data\n",
        "\n",
        "\n",
        "@beam.ptransform_fn \n",
        "def image_to_example(\n",
        "      pipeline: beam.Pipeline,\n",
        "      exec_properties: Dict[Text, Any],\n",
        "      split_pattern: Text,\n",
        "      ) -> beam.pvalue.PCollection:\n",
        "    \"\"\"Read jpeg files and transform to TF examples.\n",
        "\n",
        "    Note that each input split will be transformed by this function separately.\n",
        "\n",
        "    Args:\n",
        "        pipeline: beam pipeline.\n",
        "        input_dict: Input dict from input key to a list of Artifacts.\n",
        "          - input_base: input dir that contains the image data.\n",
        "        exec_properties: A dict of execution properties.\n",
        "        split_pattern: Split.pattern in Input config, glob relative file pattern\n",
        "          that maps to input files with root directory given by input_base.\n",
        "\n",
        "    Returns:\n",
        "        PCollection of TF examples.\n",
        "    \"\"\"\n",
        "    input_base_uri = exec_properties[utils.INPUT_BASE_KEY]\n",
        "    image_pattern = os.path.join(input_base_uri, split_pattern)\n",
        "    absl.logging.info(\n",
        "        'Processing input image data {} to TFExample.'.format(image_pattern))\n",
        "\n",
        "    image_files = tf.io.gfile.glob(image_pattern)\n",
        "    if not image_files:\n",
        "        raise RuntimeError(\n",
        "            'Split pattern {} does not match any files.'.format(image_pattern))\n",
        "\n",
        "    return (\n",
        "        pipeline\n",
        "        | beam.Create(image_files)\n",
        "        | 'ConvertImagesToBase64' >> beam.Map(lambda file: get_image_data(file))\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwk_iZXdyA8N"
      },
      "source": [
        "class ImageExampleGenExecutor(BaseExampleGenExecutor):\n",
        "    \"\"\"TFX example gen executor for processing jpeg format.\n",
        "\n",
        "    Example usage:\n",
        "\n",
        "      from tfx.components.example_gen.component import\n",
        "      FileBasedExampleGen\n",
        "      from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "      example_gen = FileBasedExampleGen(\n",
        "          input=external_input(\"/content/PetImages/\"),\n",
        "          input_config=input_config,\n",
        "          output_config=output,\n",
        "          custom_executor_spec=executor_spec.ExecutorClassSpec(_Executor))\n",
        "    \"\"\"\n",
        "\n",
        "    def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n",
        "        \"\"\"Returns PTransform for image to TF examples.\"\"\"\n",
        "        return image_to_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzWHV-LbesyZ"
      },
      "source": [
        "## Building your ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlAmd4aSj03V"
      },
      "source": [
        "pipeline_name = \"dogs_cats_pipeline\"\n",
        "\n",
        "context = InteractiveContext(pipeline_name=pipeline_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpUFbbLzyHpm"
      },
      "source": [
        "output = example_gen_pb2.Output(\n",
        "    split_config=example_gen_pb2.SplitConfig(splits=[\n",
        "        example_gen_pb2.SplitConfig.Split(\n",
        "            name='train',\n",
        "            hash_buckets=4\n",
        "        ),\n",
        "        example_gen_pb2.SplitConfig.Split(\n",
        "            name='eval',\n",
        "            hash_buckets=1\n",
        "        )\n",
        "    ])\n",
        ")\n",
        "\n",
        "input_config = example_gen_pb2.Input(splits=[\n",
        "    example_gen_pb2.Input.Split(name='images', pattern='*.jpg'),\n",
        "])\n",
        "\n",
        "example_gen = FileBasedExampleGen(\n",
        "    input=external_input(\"/content/images/\"),\n",
        "    input_config=input_config,\n",
        "    output_config=output,\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(ImageExampleGenExecutor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4WKPHrCbzlT"
      },
      "source": [
        "context.run(example_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5acSHe-yQaa"
      },
      "source": [
        "statistics_gen = StatisticsGen(\n",
        "    examples=example_gen.outputs['examples']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNNuYiKXbfnR"
      },
      "source": [
        "context.run(statistics_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2V0mMsxb53i"
      },
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKMamzVJcBOu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}