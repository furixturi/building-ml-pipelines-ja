{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "differential_privacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke3Z3T-DPLMu"
      },
      "source": [
        "# Data Privacy\n",
        "\n",
        "- パッケージインストール後、ランタイムを再起動すること（Colab）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gKxHKrquqhm"
      },
      "source": [
        "## Setup\n",
        "### Install the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5GVnk0RPLMv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27290c54-4b79-4014-bf82-3579677ce092"
      },
      "source": [
        "!pip install tensorflow_privacy==0.5.1\n",
        "!pip install tensorflow==2.4.1 pandas==1.2.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_privacy==0.5.1\n",
            "  Downloading tensorflow_privacy-0.5.1-py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 40 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 81 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 112 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 122 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 133 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 143 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (1.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (2.6.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (0.1.6)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree~=0.1.1->tensorflow_privacy==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.17->tensorflow_privacy==0.5.1) (1.19.5)\n",
            "Installing collected packages: tensorflow-privacy\n",
            "Successfully installed tensorflow-privacy-0.5.1\n",
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 13 kB/s \n",
            "\u001b[?25hCollecting pandas==1.2.3\n",
            "  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 41 kB/s \n",
            "\u001b[?25hCollecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.6.0)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2.8.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.5.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow, pandas\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.39.0\n",
            "    Uninstalling grpcio-1.39.0:\n",
            "      Successfully uninstalled grpcio-1.39.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.3 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 pandas-1.2.3 tensorflow-2.4.1 tensorflow-estimator-2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYoEIy0KutgB",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Import the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N10jj3R47Sj"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4nXotGYuvs5"
      },
      "source": [
        "## The dataset\n",
        "\n",
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dBURN1ZYURl"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I535-Fw6XeUc"
      },
      "source": [
        "\n",
        "# Initial dataset source\n",
        "DATASET_URL = \"http://bit.ly/building-ml-pipelines-dataset\"\n",
        "\n",
        "# Initial local dataset location\n",
        "LOCAL_FILE_NAME = \"data/consumer_complaints_with_narrative.csv\"\n",
        "\n",
        "\n",
        "def download_dataset(url=DATASET_URL):\n",
        "    \"\"\"download_dataset downloads the remote dataset to a local path\n",
        "\n",
        "    Keyword Arguments:\n",
        "        url {string} --\n",
        "            complete url path to the csv data source (default: {DATASET_URL})\n",
        "        local_path {string} --\n",
        "            initial local file location (default: {LOCAL_FILE_NAME})\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(url, index_col=0)\n",
        "    df.to_csv(LOCAL_FILE_NAME)\n",
        "    logging.info(\"Download completed.\")\n",
        "\n",
        "\n",
        "download_dataset()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTUf1Zreu4Cu",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o-EurrDk7Fi"
      },
      "source": [
        "feature_names = [\"product\", \"sub_product\", \"issue\", \"sub_issue\", \"consumer_complaint_narrative\", \"company\", \"state\", \"zip_code\", \"company_response\", \"timely_response\", \"consumer_disputed\"]\n",
        "df = pd.read_csv(LOCAL_FILE_NAME, usecols=feature_names)\n",
        "df = df.head(66000)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep69FHWVPLM3"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lDj1OJCWfTy"
      },
      "source": [
        "ONE_HOT_FEATURES = {\n",
        "    \"product\": None,\n",
        "    \"sub_product\": None,\n",
        "    \"company_response\": None,\n",
        "    \"state\": None,\n",
        "    \"issue\": None\n",
        "}\n",
        "\n",
        "# feature name, bucket count\n",
        "BUCKET_FEATURES = {\n",
        "    \"zip_code\": 10\n",
        "}\n",
        "\n",
        "# feature name, value is unused\n",
        "TEXT_FEATURES = {\n",
        "    \"consumer_complaint_narrative\": None\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH5SAgmOOL6K"
      },
      "source": [
        "def make_one_hot(df):\n",
        "    one_hot_array = []\n",
        "    for feature_name in ONE_HOT_FEATURES.keys():\n",
        "        temp_array = pd.np.asarray(tf.keras.utils.to_categorical(df[feature_name].values))\n",
        "        ONE_HOT_FEATURES[feature_name] = temp_array.shape[1]\n",
        "        one_hot_array.append(temp_array)\n",
        "\n",
        "    return one_hot_array"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxbSJIw3lDOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "b31c7d52-11e1-4494-e290-ceba5bdec9da"
      },
      "source": [
        "for feature in ONE_HOT_FEATURES.keys():\n",
        "    df[feature] = df[feature].astype(\"category\").cat.codes\n",
        "\n",
        "one_hot_x = make_one_hot(df)\n",
        "\n",
        "embedding_x = [pd.np.asarray(df[feature_name].values).reshape(-1) for feature_name in TEXT_FEATURES.keys()]\n",
        "\n",
        "df['zip_code'] = df['zip_code'].str.replace('X', '0', regex=True)\n",
        "df['zip_code'] = df['zip_code'].str.replace(r'\\[|\\*|\\+|\\-|`|\\.|\\ |\\$|\\/|!|\\(', '0', regex=True)\n",
        "df['zip_code'] = df['zip_code'].fillna(0)\n",
        "df['zip_code'] = df['zip_code'].astype('int32')\n",
        "# one bucket per 10k\n",
        "df['zip_code'] = df['zip_code'].apply(lambda x: x//10000)\n",
        "numeric_x = [df['zip_code'].values]\n",
        "\n",
        "X = one_hot_x + numeric_x + embedding_x\n",
        "y = np.asarray(df[\"consumer_disputed\"], dtype=np.uint8).reshape(-1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Eo3zrCVRPm",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Adding DP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yto8Cmn7VErQ"
      },
      "source": [
        "# DP parameters\n",
        "NOISE_MULTIPLIER = 1.1\n",
        "NUM_MICROBATCHES = 30\n",
        "LEARNING_RATE = 0.1\n",
        "POPULATION_SIZE = 1000\n",
        "L2_NORM_CLIP = 1.0\n",
        "BATCH_SIZE = 30\n",
        "EPOCHS = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0JJ_EnmVTk6"
      },
      "source": [
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
        "\n",
        "optimizer = DPKerasSGDOptimizer(\n",
        "        l2_norm_clip=L2_NORM_CLIP,\n",
        "        noise_multiplier=NOISE_MULTIPLIER,\n",
        "        num_microbatches=NUM_MICROBATCHES,\n",
        "        learning_rate=LEARNING_RATE\n",
        ")\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy(\n",
        "        from_logits=True,\n",
        "        reduction=tf.losses.Reduction.NONE\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoQHOGsh5Anr"
      },
      "source": [
        "The model is unchanged, we just pass in the differentially private optimizer and loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ7Z1LHd4-kb"
      },
      "source": [
        "def transformed_name(key):\n",
        "    return key + '_xf'\n",
        "\n",
        "def get_model(dp_optimizer, dp_loss, show_summary=True):\n",
        "    \"\"\"\n",
        "    This function defines a Keras model and returns the model as a Keras object.\n",
        "    \"\"\"\n",
        "\n",
        "    # one-hot categorical features\n",
        "    input_features = []\n",
        "    for key, dim in ONE_HOT_FEATURES.items():\n",
        "        input_features.append(tf.keras.Input(shape=(dim), name=transformed_name(key)))\n",
        "\n",
        "    # adding bucketized features\n",
        "    for key, dim in BUCKET_FEATURES.items():\n",
        "        input_features.append(tf.keras.Input(1, name=transformed_name(key)))\n",
        "\n",
        "    # adding text input features\n",
        "    input_texts = []\n",
        "    for key in TEXT_FEATURES.keys():\n",
        "        input_texts.append(tf.keras.Input(shape=(1,), name=transformed_name(key), dtype=tf.string))\n",
        "\n",
        "    # embed text features\n",
        "    MODULE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "    embed = hub.KerasLayer(MODULE_URL)\n",
        "    reshaped_narrative = tf.reshape(input_texts[0], [-1])\n",
        "    embed_narrative = embed(reshaped_narrative)\n",
        "    deep_ff = tf.keras.layers.Reshape((512, ), input_shape=(1, 512))(embed_narrative)\n",
        "\n",
        "    deep = tf.keras.layers.Dense(256, activation='relu')(deep_ff)\n",
        "    deep = tf.keras.layers.Dense(64, activation='relu')(deep)\n",
        "    deep = tf.keras.layers.Dense(16, activation='relu')(deep)\n",
        "\n",
        "    wide_ff = tf.keras.layers.concatenate(input_features)\n",
        "    wide = tf.keras.layers.Dense(16, activation='relu')(wide_ff)\n",
        "\n",
        "    both = tf.keras.layers.concatenate([deep, wide])\n",
        "\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(both)\n",
        "\n",
        "    inputs = input_features + input_texts\n",
        "\n",
        "    keras_model = tf.keras.models.Model(inputs, output)\n",
        "    keras_model.compile(optimizer=dp_optimizer,\n",
        "                        loss=dp_loss,\n",
        "                        metrics=[\n",
        "                            tf.keras.metrics.BinaryAccuracy(),\n",
        "                            tf.keras.metrics.TruePositives()\n",
        "                        ])\n",
        "    if show_summary:\n",
        "        keras_model.summary()\n",
        "\n",
        "    return keras_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Cq6eZe3JbEZI"
      },
      "source": [
        "model = get_model(show_summary=False, dp_optimizer=optimizer, dp_loss=loss)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5qNosEMbEZI",
        "outputId": "3b4be3ae-02ff-4fac-96a7-180026d8e4f0"
      },
      "source": [
        "model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1980/1980 [==============================] - 121s 58ms/step - loss: 0.7519 - binary_accuracy: 0.7661 - true_positives: 0.0000e+00 - val_loss: 0.7532 - val_binary_accuracy: 0.7814 - val_true_positives: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc114cc5a10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7dZFjtibbEZI"
      },
      "source": [
        "### Calculate Epsilon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDZKbP_PbEZI",
        "outputId": "387d9e7c-593e-4e26-9dcc-e5a4f321085e"
      },
      "source": [
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "\n",
        "\n",
        "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
        "    n=POPULATION_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    noise_multiplier=NOISE_MULTIPLIER,\n",
        "    epochs=EPOCHS,\n",
        "    delta=1e-3\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DP-SGD with sampling rate = 3% and noise_multiplier = 1.1 iterated over 34 steps satisfies differential privacy with eps = 1.32 and delta = 0.001.\n",
            "The optimal RDP order is 8.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.319747955364283, 8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4TTGI9glD_M"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAmaGolZl4cX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283a2e87-62c6-4a9b-bcff-5e905e0f3316"
      },
      "source": [
        "model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1980/1980 [==============================] - 109s 55ms/step - loss: 0.8534 - binary_accuracy: 0.7654 - true_positives: 0.0000e+00 - val_loss: 0.8285 - val_binary_accuracy: 0.7814 - val_true_positives: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc027e35110>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1gtS5tFfZau"
      },
      "source": [
        "### Calculate Epsilon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6u5MIUkMrpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d075456-8d5d-419e-bc18-087167e579af"
      },
      "source": [
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "\n",
        "\n",
        "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
        "    n=POPULATION_SIZE, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    noise_multiplier=NOISE_MULTIPLIER, \n",
        "    epochs=EPOCHS, \n",
        "    delta=1e-3\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DP-SGD with sampling rate = 3% and noise_multiplier = 1.1 iterated over 34 steps satisfies differential privacy with eps = 1.32 and delta = 0.001.\n",
            "The optimal RDP order is 8.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.319747955364283, 8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBzK9bK1gBab"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}