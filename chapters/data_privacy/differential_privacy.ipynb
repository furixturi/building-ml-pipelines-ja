{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "differential_privacy.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke3Z3T-DPLMu"
   },
   "source": [
    "# Data Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gKxHKrquqhm"
   },
   "source": [
    "## Setup\n",
    "### Install the packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V5GVnk0RPLMv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e035d686-ad21-4292-f21a-268587fd2ee9"
   },
   "source": [
    "!pip install tensorflow_privacy==0.5.1\n",
    "!pip install tensorflow==2.4.1 pandas==1.2.3"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_privacy==0.5.1 in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (1.4.1)\n",
      "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (1.2.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (0.1.5)\n",
      "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.5.1) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.17->tensorflow_privacy==0.5.1) (1.19.5)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree~=0.1.1->tensorflow_privacy==0.5.1) (1.15.0)\n",
      "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
      "Requirement already satisfied: pandas==1.2.3 in /usr/local/lib/python3.7/dist-packages (1.2.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.12.4)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.10.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2018.9)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (54.1.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYoEIy0KutgB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4N10jj3R47Sj"
   },
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4nXotGYuvs5"
   },
   "source": [
    "## The dataset\n",
    "\n",
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dBURN1ZYURl",
    "outputId": "0c4f35a8-fc06-4c9e-bfe8-1657510d69d9"
   },
   "source": [
    "!mkdir data"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I535-Fw6XeUc"
   },
   "source": [
    "\n",
    "# Initial dataset source\n",
    "DATASET_URL = \"http://bit.ly/building-ml-pipelines-dataset\"\n",
    "\n",
    "# Initial local dataset location\n",
    "LOCAL_FILE_NAME = \"data/consumer_complaints_with_narrative.csv\"\n",
    "\n",
    "\n",
    "def download_dataset(url=DATASET_URL):\n",
    "    \"\"\"download_dataset downloads the remote dataset to a local path\n",
    "\n",
    "    Keyword Arguments:\n",
    "        url {string} --\n",
    "            complete url path to the csv data source (default: {DATASET_URL})\n",
    "        local_path {string} --\n",
    "            initial local file location (default: {LOCAL_FILE_NAME})\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(url, index_col=0)\n",
    "    df.to_csv(LOCAL_FILE_NAME)\n",
    "    logging.info(\"Download completed.\")\n",
    "\n",
    "\n",
    "download_dataset()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTUf1Zreu4Cu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3o-EurrDk7Fi"
   },
   "source": [
    "feature_names = [\"product\", \"sub_product\", \"issue\", \"sub_issue\", \"consumer_complaint_narrative\", \"company\", \"state\", \"zip_code\", \"company_response\", \"timely_response\", \"consumer_disputed\"]\n",
    "df = pd.read_csv(LOCAL_FILE_NAME, usecols=feature_names)\n",
    "df = df.head(66000)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep69FHWVPLM3"
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5lDj1OJCWfTy"
   },
   "source": [
    "ONE_HOT_FEATURES = {\n",
    "    \"product\": None,\n",
    "    \"sub_product\": None,\n",
    "    \"company_response\": None,\n",
    "    \"state\": None,\n",
    "    \"issue\": None\n",
    "}\n",
    "\n",
    "# feature name, bucket count\n",
    "BUCKET_FEATURES = {\n",
    "    \"zip_code\": 10\n",
    "}\n",
    "\n",
    "# feature name, value is unused\n",
    "TEXT_FEATURES = {\n",
    "    \"consumer_complaint_narrative\": None\n",
    "}"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nH5SAgmOOL6K"
   },
   "source": [
    "def make_one_hot(df):\n",
    "    one_hot_array = []\n",
    "    for feature_name in ONE_HOT_FEATURES.keys():\n",
    "        temp_array = pd.np.asarray(tf.keras.utils.to_categorical(df[feature_name].values))\n",
    "        ONE_HOT_FEATURES[feature_name] = temp_array.shape[1]\n",
    "        one_hot_array.append(temp_array)\n",
    "\n",
    "    return one_hot_array"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jxbSJIw3lDOj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "06ba7c40-e152-4b24-8981-00093a6b8e68",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "for feature in ONE_HOT_FEATURES.keys():\n",
    "    df[feature] = df[feature].astype(\"category\").cat.codes\n",
    "\n",
    "one_hot_x = make_one_hot(df)\n",
    "\n",
    "embedding_x = [pd.np.asarray(df[feature_name].values).reshape(-1) for feature_name in TEXT_FEATURES.keys()]\n",
    "\n",
    "df['zip_code'] = df['zip_code'].str.replace('X', '0', regex=True)\n",
    "df['zip_code'] = df['zip_code'].str.replace(r'\\[|\\*|\\+|\\-|`|\\.|\\ |\\$|\\/|!|\\(', '0', regex=True)\n",
    "df['zip_code'] = df['zip_code'].fillna(0)\n",
    "df['zip_code'] = df['zip_code'].astype('int32')\n",
    "# one bucket per 10k\n",
    "df['zip_code'] = df['zip_code'].apply(lambda x: x//10000)\n",
    "numeric_x = [df['zip_code'].values]\n",
    "\n",
    "X = one_hot_x + numeric_x + embedding_x\n",
    "y = np.asarray(df[\"consumer_disputed\"], dtype=np.uint8).reshape(-1)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9Eo3zrCVRPm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Adding DP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yto8Cmn7VErQ"
   },
   "source": [
    "# DP parameters\n",
    "NOISE_MULTIPLIER = 1.1\n",
    "NUM_MICROBATCHES = 30\n",
    "LEARNING_RATE = 0.1\n",
    "POPULATION_SIZE = 1000\n",
    "L2_NORM_CLIP = 1.0\n",
    "BATCH_SIZE = 30\n",
    "EPOCHS = 1"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u0JJ_EnmVTk6"
   },
   "source": [
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "\n",
    "optimizer = DPKerasSGDOptimizer(\n",
    "        l2_norm_clip=L2_NORM_CLIP,\n",
    "        noise_multiplier=NOISE_MULTIPLIER,\n",
    "        num_microbatches=NUM_MICROBATCHES,\n",
    "        learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(\n",
    "        from_logits=True,\n",
    "        reduction=tf.losses.Reduction.NONE\n",
    ")"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoQHOGsh5Anr"
   },
   "source": [
    "The model is unchanged, we just pass in the differentially private optimizer and loss."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JZ7Z1LHd4-kb"
   },
   "source": [
    "def transformed_name(key):\n",
    "    return key + '_xf'\n",
    "\n",
    "def get_model(dp_optimizer, dp_loss, show_summary=True):\n",
    "    \"\"\"\n",
    "    This function defines a Keras model and returns the model as a Keras object.\n",
    "    \"\"\"\n",
    "\n",
    "    # one-hot categorical features\n",
    "    input_features = []\n",
    "    for key, dim in ONE_HOT_FEATURES.items():\n",
    "        input_features.append(tf.keras.Input(shape=(dim), name=transformed_name(key)))\n",
    "\n",
    "    # adding bucketized features\n",
    "    for key, dim in BUCKET_FEATURES.items():\n",
    "        input_features.append(tf.keras.Input(1, name=transformed_name(key)))\n",
    "\n",
    "    # adding text input features\n",
    "    input_texts = []\n",
    "    for key in TEXT_FEATURES.keys():\n",
    "        input_texts.append(tf.keras.Input(shape=(1,), name=transformed_name(key), dtype=tf.string))\n",
    "\n",
    "    # embed text features\n",
    "    MODULE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "    embed = hub.KerasLayer(MODULE_URL)\n",
    "    reshaped_narrative = tf.reshape(input_texts[0], [-1])\n",
    "    embed_narrative = embed(reshaped_narrative)\n",
    "    deep_ff = tf.keras.layers.Reshape((512, ), input_shape=(1, 512))(embed_narrative)\n",
    "\n",
    "    deep = tf.keras.layers.Dense(256, activation='relu')(deep_ff)\n",
    "    deep = tf.keras.layers.Dense(64, activation='relu')(deep)\n",
    "    deep = tf.keras.layers.Dense(16, activation='relu')(deep)\n",
    "\n",
    "    wide_ff = tf.keras.layers.concatenate(input_features)\n",
    "    wide = tf.keras.layers.Dense(16, activation='relu')(wide_ff)\n",
    "\n",
    "    both = tf.keras.layers.concatenate([deep, wide])\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(both)\n",
    "\n",
    "    inputs = input_features + input_texts\n",
    "\n",
    "    keras_model = tf.keras.models.Model(inputs, output)\n",
    "    keras_model.compile(optimizer=dp_optimizer,\n",
    "                        loss=dp_loss,\n",
    "                        metrics=[\n",
    "                            tf.keras.metrics.BinaryAccuracy(),\n",
    "                            tf.keras.metrics.TruePositives()\n",
    "                        ])\n",
    "    if show_summary:\n",
    "        keras_model.summary()\n",
    "\n",
    "    return keras_model"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = get_model(show_summary=False, dp_optimizer=optimizer, dp_loss=loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Epsilon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "\n",
    "\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    n=POPULATION_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    noise_multiplier=NOISE_MULTIPLIER,\n",
    "    epochs=EPOCHS,\n",
    "    delta=1e-3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y4TTGI9glD_M"
   },
   "source": [],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yAmaGolZl4cX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "256f2c01-e3b6-489b-dee8-89f3bd21ddff"
   },
   "source": [
    "model.fit(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS\n",
    ")"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "1980/1980 [==============================] - 195s 95ms/step - loss: 0.7740 - binary_accuracy: 0.7656 - true_positives: 0.9995 - val_loss: 0.7648 - val_binary_accuracy: 0.7814 - val_true_positives: 0.0000e+00\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92493c7c10>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1gtS5tFfZau"
   },
   "source": [
    "### Calculate Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q6u5MIUkMrpS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1fca01cf-f971-4c5c-c016-0f7c04bcd5bf"
   },
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "\n",
    "\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    n=POPULATION_SIZE, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    noise_multiplier=NOISE_MULTIPLIER, \n",
    "    epochs=EPOCHS, \n",
    "    delta=1e-3\n",
    ")"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 3% and noise_multiplier = 1.1 iterated over 34 steps satisfies differential privacy with eps = 1.32 and delta = 0.001.\n",
      "The optimal RDP order is 8.0.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.319747955364283, 8.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gBzK9bK1gBab"
   },
   "source": [
    ""
   ],
   "execution_count": 14,
   "outputs": []
  }
 ]
}